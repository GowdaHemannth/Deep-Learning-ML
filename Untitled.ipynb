{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f30dfc3-ee9e-487e-acf4-a25ea008f3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorflow) (78.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.32.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.23.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "277a43e7-ca60-4c0c-9962-385400898332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e479a254-c09c-4a86-aab9-12b754b3cb62",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4b471dc-9e4e-40b3-89e1-d6bd439c8faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here thatkeras.datasest is a Api which collects api and load the api the present it \n",
    "(X_train,y_train),(X_test,y_test)=keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9794e14-54bc-47de-b7ef-784435fbe369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b566ca30-4dcc-46d4-81e2-dfce58826c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d352532730>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eceb354-639e-41c1-b68d-7397ef82824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## here now we need to flatten the Array from 2d to one \n",
    "## Here i need to scaling which willincrease my Accuracy Speed \n",
    "X_train=X_train/255\n",
    "X_test=X_test/255\n",
    "X_train_flattened=X_train.reshape(len(X_train),28*28)\n",
    "X_test_flattened=X_test.reshape(len(X_test),28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a1cd1ee-7f8a-49de-b3bf-446220fba171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 821us/step - loss: 0.4716 - accuracy: 0.8770\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 735us/step - loss: 0.3041 - accuracy: 0.9151\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 726us/step - loss: 0.2836 - accuracy: 0.9202\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 741us/step - loss: 0.2729 - accuracy: 0.9236\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 697us/step - loss: 0.2666 - accuracy: 0.9259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d351eb3b80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Defining Neurol network model \n",
    "model=keras.Sequential([\n",
    "    keras.layers.Dense(10,input_shape=(784,),activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy']\n",
    "    \n",
    ")\n",
    "model.fit(X_train_flattened,y_train,epochs=5)\n",
    "\n",
    "## Here as we can see Scaling as eventually Incresed the Accuracy then Has reduced the Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40216bfa-35fc-44eb-9cbc-150d5ef9e89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 605us/step - loss: 0.2689 - accuracy: 0.9254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26892220973968506, 0.9254000186920166]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## There we saw accuarcy to the Tarining Daatset Now as you can See We need to Test the Testing Dataset \n",
    "model.evaluate(X_test_flattened,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae006217-7779-4bb0-9b13-7b20aeae002b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install pandas \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23cac138-d4fb-47e7-95cb-08276301cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here you will be getting to know Gardient descent Means \n",
    "## Basicalyy Gardient Descent Means How do you Calculate or Minimize the Loss \n",
    "import pandas as pd\n",
    "base_path = pd.read_csv(\"insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aa904b6-f96c-49f6-aad7-52daf2d1fc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordability</th>\n",
       "      <th>will_buy_insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  affordability  will_buy_insurance\n",
       "0   19              1                   1\n",
       "1   18              1                   1\n",
       "2   28              0                   0\n",
       "3   33              0                   0\n",
       "4   32              0                   0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1422dc1-8f0d-4c2f-8295-58a1612ee411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5fead1d-9bc0-4591-9975-fa18cba19174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "603c21aa-f0ef-4d9e-8a84-98b0633a7225",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    base_path[['age', 'affordability']],\n",
    "    base_path['will_buy_insurance'],\n",
    "    test_size=0.2,\n",
    "    random_state=25\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb115d1-9652-48d4-a79a-0cbe1b554cbc",
   "metadata": {},
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e1700c7-5e92-4e45-86a3-b71462989791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fb8a9c5-152c-4590-a1c8-70aedad3768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Next step is to usE Scaling Here we have already Scaled many Thing here only thing which needs to be scaled is Age \n",
    "X_train_scaled=X_train.copy()\n",
    "X_train_scaled['age']=X_train_scaled['age']/100\n",
    "\n",
    "X_test_scaled=X_test.copy()\n",
    "X_test_scaled['age']=X_test_scaled['age']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aa40078-615e-4e7e-b235-03ae31fe0533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  affordability\n",
       "28  0.23              1\n",
       "10  0.25              1\n",
       "9   0.60              0\n",
       "0   0.19              1\n",
       "6   0.46              0\n",
       "19  0.30              1\n",
       "16  0.52              0\n",
       "13  0.56              0\n",
       "27  0.55              0\n",
       "17  0.23              1\n",
       "3   0.33              0\n",
       "7   0.37              1\n",
       "1   0.18              1\n",
       "5   0.31              0\n",
       "20  0.60              0\n",
       "30  0.22              1\n",
       "8   0.37              0\n",
       "18  0.56              0\n",
       "12  0.23              0\n",
       "23  0.34              0\n",
       "22  0.18              1\n",
       "15  0.19              1\n",
       "26  0.63              0\n",
       "4   0.32              0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3300e700-d561-4c85-b8c4-e157ad28b001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.6600 - accuracy: 0.4167\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.4167\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6590 - accuracy: 0.4167\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6585 - accuracy: 0.4167\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6580 - accuracy: 0.4167\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6575 - accuracy: 0.4167\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6570 - accuracy: 0.4167\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6565 - accuracy: 0.4167\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6560 - accuracy: 0.4167\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6555 - accuracy: 0.4167\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.4167\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.4167\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.4167\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.4167\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.4167\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6525 - accuracy: 0.4167\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.4167\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.4167\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6511 - accuracy: 0.4167\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6506 - accuracy: 0.4167\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.4167\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.4167\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6491 - accuracy: 0.4167\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6486 - accuracy: 0.4167\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6481 - accuracy: 0.4167\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6476 - accuracy: 0.4167\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6471 - accuracy: 0.4167\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.4167\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6461 - accuracy: 0.4167\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6457 - accuracy: 0.4167\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6452 - accuracy: 0.4167\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.4167\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.4167\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6437 - accuracy: 0.4167\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6432 - accuracy: 0.4167\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6427 - accuracy: 0.4167\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.4167\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.4167\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.4167\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6408 - accuracy: 0.4167\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.4167\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.4167\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.4167\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6388 - accuracy: 0.4167\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6384 - accuracy: 0.4167\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6379 - accuracy: 0.4167\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.4167\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.4167\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.4167\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.4167\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.4167\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.4167\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.4167\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6340 - accuracy: 0.4167\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6336 - accuracy: 0.4167\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.4167\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.4167\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6321 - accuracy: 0.4167\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.4167\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.4167\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6307 - accuracy: 0.4167\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6302 - accuracy: 0.4167\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6297 - accuracy: 0.4167\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.4167\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6288 - accuracy: 0.4167\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6283 - accuracy: 0.4167\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6278 - accuracy: 0.4167\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.4167\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.4167\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6264 - accuracy: 0.4167\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6260 - accuracy: 0.4167\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6255 - accuracy: 0.4167\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.4167\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6245 - accuracy: 0.4167\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6241 - accuracy: 0.4167\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.4167\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.4167\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6227 - accuracy: 0.4167\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.4167\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6217 - accuracy: 0.4167\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6213 - accuracy: 0.4167\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6208 - accuracy: 0.4167\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.4167\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.4167\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6194 - accuracy: 0.4167\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.4167\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.4167\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.4167\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6175 - accuracy: 0.4167\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.4167\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.4167\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6161 - accuracy: 0.4167\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6157 - accuracy: 0.4167\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6152 - accuracy: 0.4167\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.4167\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.4167\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.4167\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6134 - accuracy: 0.4167\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.4167\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6125 - accuracy: 0.4167\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6120 - accuracy: 0.4167\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6115 - accuracy: 0.4167\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6111 - accuracy: 0.4167\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6106 - accuracy: 0.4167\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6102 - accuracy: 0.4167\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6097 - accuracy: 0.4167\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6093 - accuracy: 0.4167\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6088 - accuracy: 0.4167\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6083 - accuracy: 0.4167\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6079 - accuracy: 0.4167\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6074 - accuracy: 0.4167\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.4167\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6065 - accuracy: 0.4167\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.4167\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6056 - accuracy: 0.4167\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6052 - accuracy: 0.4167\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6047 - accuracy: 0.4167\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6043 - accuracy: 0.4167\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.4167\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6034 - accuracy: 0.4167\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6029 - accuracy: 0.4167\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6025 - accuracy: 0.4167\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6020 - accuracy: 0.4167\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.4167\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.4167\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6007 - accuracy: 0.4167\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6002 - accuracy: 0.4167\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5998 - accuracy: 0.4167\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5993 - accuracy: 0.4167\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5989 - accuracy: 0.4167\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5984 - accuracy: 0.4167\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5980 - accuracy: 0.4167\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5975 - accuracy: 0.4167\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.4167\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.4167\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5962 - accuracy: 0.4167\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.4167\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5953 - accuracy: 0.4167\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.4167\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5944 - accuracy: 0.4167\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5940 - accuracy: 0.4167\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5936 - accuracy: 0.4167\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5931 - accuracy: 0.4167\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5927 - accuracy: 0.4167\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5922 - accuracy: 0.4167\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5918 - accuracy: 0.4167\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5914 - accuracy: 0.4167\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5909 - accuracy: 0.4167\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.4167\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5900 - accuracy: 0.4167\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5896 - accuracy: 0.4167\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.4167\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5887 - accuracy: 0.4167\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.4167\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5879 - accuracy: 0.4167\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.4167\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.4167\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.4167\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5861 - accuracy: 0.4167\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.4167\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.4167\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.4167\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.4167\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.4167\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.4167\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.4167\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.4167\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.4167\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.4167\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.4167\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.4167\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.4167\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.4167\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5797 - accuracy: 0.4167\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5792 - accuracy: 0.4167\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.4167\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.4167\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.4167\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.4167\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5771 - accuracy: 0.4167\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.4167\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.4167\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.4167\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5754 - accuracy: 0.4167\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5750 - accuracy: 0.4167\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.4167\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.4167\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5737 - accuracy: 0.4167\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.4167\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5729 - accuracy: 0.4167\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.4167\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.4167\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.4167\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5712 - accuracy: 0.4167\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.4583\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.4583\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.4583\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.4583\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.4583\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.4583\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.4583\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.4583\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.4583\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.4583\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.4583\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.4583\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.4583\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.4583\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.4583\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.4583\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5641 - accuracy: 0.4583\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.4583\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.4583\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.4583\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.4583\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.4583\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.4583\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.4583\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5608 - accuracy: 0.4583\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.4583\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.4583\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.4583\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.4583\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.4583\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.4583\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.4583\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.4583\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.4583\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.4583\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.4583\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.4583\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.4583\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.4583\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.4583\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.4583\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.4583\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.4583\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.4583\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.4583\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.4583\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.4583\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.4583\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.4583\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5507 - accuracy: 0.4583\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.4583\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5499 - accuracy: 0.4583\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.4583\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5491 - accuracy: 0.4583\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.5000\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5483 - accuracy: 0.5000\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5479 - accuracy: 0.5000\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5475 - accuracy: 0.5000\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.5000\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.5000\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.5417\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.5417\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.5417\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.5417\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.5417\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.5417\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.5417\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.5833\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5431 - accuracy: 0.5833\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.5833\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.5833\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5420 - accuracy: 0.5833\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.5833\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.6250\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.6250\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.6250\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.6250\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5396 - accuracy: 0.6250\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.6250\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.6250\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.6250\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.6250\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.6250\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.6250\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.6250\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.6250\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.6250\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.6250\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.6250\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.6250\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.6250\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.6667\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.6667\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.6667\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5331 - accuracy: 0.6667\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5327 - accuracy: 0.6667\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5323 - accuracy: 0.6667\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5319 - accuracy: 0.6667\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.6667\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.6667\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.6667\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.6667\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.6667\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.6667\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.6667\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5289 - accuracy: 0.6667\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5285 - accuracy: 0.6667\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.6667\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.6667\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.6667\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.6667\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.6667\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.6667\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.6667\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.6667\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.6667\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.6667\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.6667\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.6667\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.6667\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.6667\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.6667\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5225 - accuracy: 0.6667\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.6667\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.6667\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.6667\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.6667\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.6667\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5203 - accuracy: 0.6667\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.6667\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5195 - accuracy: 0.6667\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.6667\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.6667\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5184 - accuracy: 0.6667\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.6667\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.6667\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.6667\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.6667\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.6667\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.6667\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.6667\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.6667\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7083\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7083\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7083\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7083\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7083\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7083\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7083\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7083\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7083\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7083\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7083\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7083\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7083\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7083\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7083\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7083\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7083\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7083\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7083\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7083\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7083\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7083\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7083\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7083\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7083\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7083\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7083\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7083\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7083\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7083\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7083\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7500\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7500\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7500\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7500\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7500\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7500\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7500\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7500\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.7500\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7500\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7500\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7500\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7500\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.7500\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7500\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7917\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4983 - accuracy: 0.7917\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.7917\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7917\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.7917\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4970 - accuracy: 0.8750\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4966 - accuracy: 0.8750\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.8750\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.8750\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.8750\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.8750\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.8750\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.8750\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.8750\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.8750\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.8750\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.8750\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.8750\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.8750\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.8750\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.8750\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.8750\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.8750\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.9583\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.9583\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.9583\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.9583\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.9583\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.9583\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.9583\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.9583\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.9583\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.9583\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.9583\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.9583\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.9583\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.9583\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4857 - accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4761 - accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4731 - accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d351ecbcd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Here using keras we will be Creating the Neuron Network\n",
    "## Here The Dense Layer will be Only one \n",
    "## Here Wieght ehich means Kernel_initilazer is zero,and Bias as zero\n",
    "model=keras.Sequential([\n",
    "    keras.layers.Dense(1,input_shape=(2,),activation='sigmoid',kernel_initializer='ones',bias_initializer='zeros')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(\n",
    "    X_train_scaled.values,  # DataFrame → NumPy\n",
    "    y_train.values,         # Series → NumPy\n",
    "    epochs=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10efb197-0ffa-4726-9081-3462d8821836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4076 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40762200951576233, 1.0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## You can evaute a Model \n",
    "model.evaluate(X_test_scaled.values,y_test.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c83090b7-a317-4482-9b96-82f19c110568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.54053766],\n",
       "        [1.5049533 ]], dtype=float32),\n",
       " array([-0.45011994], dtype=float32))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## You can know weight and bias Of the particlar Function \n",
    "coef,intercept=model.get_weights()\n",
    "coef,intercept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0538f7f-7ad5-46c7-88d5-0344b046668b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999847700205"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now implemting Neuron Network From scratch \n",
    "def sigmoid(x):\n",
    "    import math\n",
    "    return 1/(1+math.exp(-x))\n",
    "sigmoid(18)    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fab9acb-ef3f-431c-821c-6b39c9ed299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_function(age,affordibility):\n",
    "    weighted_sum=coef[0]*age+coef[1]*affordibility+intercept\n",
    "    return sigmoid(weighted_sum)\n",
    "    ##Here we are doing Weighted prediction \n",
    "    ## y=w1*age+w2*afordibility+bias\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9b27257-85eb-4963-93bf-4df3f3f6ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here if you simply call prediction Function like \n",
    "## prediction_function(somevalue,somevalue) \n",
    "## These will give you the Answer \n",
    "## Here these function is Working Becuase of the we have weight And Bias \n",
    "## Here you can write your Function for the Gradient Decsent Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfacb741-4bba-43fc-8839-cf00b31bf03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>bedroom</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>55000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "      <td>125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>450</td>\n",
       "      <td>3</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600</td>\n",
       "      <td>4</td>\n",
       "      <td>225000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   area  bedroom   price\n",
       "0    45        1   25000\n",
       "1   120        2   55000\n",
       "2   300        3  125000\n",
       "3   450        3  175000\n",
       "4   600        4  225000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Here we will get to know the DIffernce Between Differnt Gardient \n",
    "\n",
    "\n",
    "Prices=pd.read_csv(\"pries.csv\")\n",
    "Prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4e82e50-e0c5-4184-9f4e-80cd9515b235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        ],\n",
       "       [0.01513623, 0.16666667],\n",
       "       [0.05146317, 0.33333333],\n",
       "       [0.08173562, 0.33333333],\n",
       "       [0.11200807, 0.5       ],\n",
       "       [0.16246216, 0.5       ],\n",
       "       [0.23309788, 0.66666667],\n",
       "       [0.29364279, 0.66666667],\n",
       "       [0.39455096, 0.83333333],\n",
       "       [0.4752775 , 0.83333333],\n",
       "       [0.06155399, 0.16666667],\n",
       "       [0.14833502, 0.33333333],\n",
       "       [0.21291625, 0.5       ],\n",
       "       [0.30575177, 0.5       ],\n",
       "       [0.41473259, 0.66666667],\n",
       "       [0.54591322, 0.66666667],\n",
       "       [0.63673058, 0.83333333],\n",
       "       [0.81836529, 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [0.14228052, 0.33333333]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing \n",
    "## Here we are Forming the Preproceesig thing \n",
    "sx=preprocessing.MinMaxScaler()\n",
    "sy=preprocessing.MinMaxScaler()\n",
    "## Here x will Contain Age, Affordibility \n",
    "## Here y will Conatin Price\n",
    "SCaled_x=sx.fit_transform(Prices.drop('price',axis='columns'))\n",
    "SCaled_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efd53e1c-5948-4f3f-81d6-02d5bfa4ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCaled_y=sy.fit_transform(Prices['price'].values.reshape(Prices.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3231a114-ffe9-4da3-b0f6-d4bd6aafb21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.01690141],\n",
       "       [0.05633803],\n",
       "       [0.08450704],\n",
       "       [0.11267606],\n",
       "       [0.15492958],\n",
       "       [0.23943662],\n",
       "       [0.27887324],\n",
       "       [0.4084507 ],\n",
       "       [0.45070423],\n",
       "       [0.07042254],\n",
       "       [0.14084507],\n",
       "       [0.21126761],\n",
       "       [0.30140845],\n",
       "       [0.4084507 ],\n",
       "       [0.48732394],\n",
       "       [0.66197183],\n",
       "       [0.83098592],\n",
       "       [1.        ],\n",
       "       [0.14366197]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCaled_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec2a93c2-b49d-4df6-aafc-0cffb12e8a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gradient_descent(X,y_true,epochs,Learning_rate=0.1):\n",
    "    number_of_Features=X.shape[1]\n",
    "    ## Here we are initializing w as 1 np.ones means that only\n",
    "    w=np.ones(shape=(number_of_Features))\n",
    "    b=0\n",
    "    total_sample=X.shape[0]\n",
    "    cost_list=[]\n",
    "    epoch_list=[]\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        ## Its nothing but \n",
    "        ## Y=w1*area+w2*Bedrooms+b\n",
    "        y_predicted=np.dot(w,SCaled_x.T)+b \n",
    "\n",
    "        ## Then now to minize the Losse We will do the Derivative \n",
    "\n",
    "        w_grad=-(2/total_sample)*(X.T.dot(y_true-y_predicted))\n",
    "        b_grad=-(2/total_sample)*np.sum(y_true-y_predicted)\n",
    "\n",
    "        w=w-Learning_rate* w_grad\n",
    "        b=b-Learning_rate* b_grad\n",
    "\n",
    "        ## Here i need to calculate loss to show that \n",
    "        cost= np.mean(np.square(y_true-y_predicted))\n",
    "\n",
    "        ## Here i want to Plot grph only on certain iterations \n",
    "        if i%10==0:\n",
    "            cost_list.append(cost)\n",
    "            epoch_list.append(i)\n",
    "    return w,b,cost,cost_list,epoch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "206a68ac-f5cf-40f0-a7aa-746277928091",
   "metadata": {},
   "outputs": [],
   "source": [
    "w,b,cost,cost_list,epoch_list= batch_gradient_descent(SCaled_x,SCaled_y.reshape(SCaled_y.shape[0],),500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "714fba4f-5c95-42de-9bc0-aafb637eb53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.76591516, 0.22859777]), -0.055093844135330486, 0.0010439039636625613)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,b,cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a9d28636-8177-41aa-a8b1-370964297ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (3.9.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.23.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\heman\\anaconda3\\envs\\t_f\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "## Now here we are gonns see how Cost varies as epoch goes\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2fb50613-efb4-4a0a-80d5-80b99c7aadd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fdd44cc8-d243-4d24-bbd1-9b925eb626a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d3022ceee0>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Here from below as you cannsee how is Cost gardualyy decresee \n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"cost\")\n",
    "plt.plot(epoch_list,cost_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ddca445e-7260-46ed-8c74-15a9b6781a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here now i want create a Function Where it shold return price fro me \n",
    "def predict(area,bedroom,w,b):\n",
    "    scaled_X=sx.transform([[area,bedroom]])[0]\n",
    "    scaled_price=w[0]*scaled_X[0]+w[1]*scaled_X[1]+b\n",
    "\n",
    "    ## here Since i transformed area and Bedroom price will be in scaled ting but i want in normal \n",
    "    return sy.inverse_transform(np.array(scaled_price).reshape(1, -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8633981e-ee2b-45d6-a45e-5e61f6511fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Heman\\anaconda3\\envs\\T_f\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[911482.1085301]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(2400,6,w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "69b45698-bcef-4d06-9243-879daf2210f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we will see how we get the BATch or Stochistastic_Grsdient \n",
    "## Here instead of Doing Dot product Thing here we will get the Random_Selected_Value\n",
    "## random_index=random.randit(0,total_samples-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ee95eb-558f-4943-9eaf-075c1be8ec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## You Ca use Tensorboard as We plotted the Graph for Cost and Epoch right like that we can Plot that asloo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
